<!--study/lesson2/lesson.wxml-->
<view class='content' bindtouchstart='handletouchstart' bindtouchmove="handletouchmove">
 <text class='maintitle'>一篇文章讲清楚人工智能、机器学习和深度学习的区别</text>
 <text class='subtitle'>第二讲</text>
 <text class='minititle'>机器学习—— 一种实现人工智能的方法</text>
 <image class='cimage' mode='aspectFit' src='https://pic.36krcnd.com/avatar/201609/07070848/91ujouvyjgk2fcwp.jpg!1200' ></image>
 <text class='imageintro'>健康食谱（Spam free diet）：机器学习能够帮你过滤电子信箱里的（大部分）垃圾邮件。（译者注：英文中垃圾邮件的单词spam来源于二战中美国曾大量援助英国的午餐肉品牌SPAM。直到六十年代，英国的农业一直没有从二战的损失中恢复，因而从美国大量进口了这种廉价的罐头肉制品。据传闻不甚好吃且充斥市场。）</text>
 <text class='lessoncontent'>机器学习最基本的做法，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测。与传统的为解决特定任务、硬编码的软件程序不同，机器学习是用大量的数据来“训练”，通过各种算法从数据中学习如何完成任务。</text>
 <text class='lessoncontent'>机器学习直接来源于早期的人工智能领域。传统算法包括决策树学习、推导逻辑规划、聚类、强化学习和贝叶斯网络等等。众所周知，我们还没有实现强人工智能。早期机器学习方法甚至都无法实现弱人工智能。</text>
 <text class='lessoncontent'>机器学习最成功的应用领域是计算机视觉，虽然也还是需要大量的手工编码来完成工作。人们需要手工编写分类器、边缘检测滤波器，以便让程序能识别物体从哪里开始，到哪里结束；写形状检测程序来判断检测对象是不是有八条边；写分类器来识别字母“ST-O-P”。使用以上这些手工编写的分类器，人们总算可以开发算法来感知图像，判断图像是不是一个停止标志牌。</text>
 <text class='lessoncontent'>这个结果还算不错，但并不是那种能让人为之一振的成功。特别是遇到云雾天，标志牌变得不是那么清晰可见，又或者被树遮挡一部分，算法就难以成功了。这就是为什么前一段时间，计算机视觉的性能一直无法接近到人的能力。它太僵化，太容易受环境条件的干扰。</text>
 <text class='lessoncontent'>随着时间的推进，学习算法的发展改变了一切。</text>
 <text class='minititle'>深度学习——一种实现机器学习的技术</text>
 <image class='cimage' mode='aspectFit' src='https://pic.36krcnd.com/avatar/201609/07071216/sekc9ixu018tbcrk.jpg!1200'></image>
 <text class='lessoncontent'>人工神经网络（Artificial Neural Networks）是早期机器学习中的一个重要的算法，历经数十年风风雨雨。神经网络的原理是受我们大脑的生理结构——互相交叉相连的神经元启发。但与大脑中一个神经元可以连接一定距离内的任意神经元不同，人工神经网络具有离散的层、连接和数据传播的方向。</text>
 <text class='lessoncontent'>例如，我们可以把一幅图像切分成图像块，输入到神经网络的第一层。在第一层的每一个神经元都把数据传递到第二层。第二层的神经元也是完成类似的工作，把数据传递到第三层，以此类推，直到最后一层，然后生成结果。</text>
 <text class='lessoncontent'>每一个神经元都为它的输入分配权重，这个权重的正确与否与其执行的任务直接相关。最终的输出由这些权重加总来决定。</text>
 <text class='lessoncontent'>我们仍以停止（Stop）标志牌为例。将一个停止标志牌图像的所有元素都打碎，然后用神经元进行“检查”：八边形的外形、救火车般的红颜色、鲜明突出的字母、交通标志的典型尺寸和静止不动运动特性等等。神经网络的任务就是给出结论，它到底是不是一个停止标志牌。神经网络会根据所有权重，给出一个经过深思熟虑的猜测——“概率向量”。</text>
 <text class='lessoncontent'>这个例子里，系统可能会给出这样的结果：86%可能是一个停止标志牌；7%的可能是一个限速标志牌；5%的可能是一个风筝挂在树上等等。然后网络结构告知神经网络，它的结论是否正确。</text>
 <text class='lessoncontent'>即使是这个例子，也算是比较超前了。直到前不久，神经网络也还是为人工智能圈所淡忘。其实在人工智能出现的早期，神经网络就已经存在了，但神经网络对于“智能”的贡献微乎其微。主要问题是，即使是最基本的神经网络，也需要大量的运算。神经网络算法的运算需求难以得到满足。</text>
 <text class='lessoncontent'>不过，还是有一些虔诚的研究团队，以多伦多大学的Geoffrey Hinton为代表，坚持研究，实现了以超算为目标的并行算法的运行与概念证明。但也直到GPU得到广泛应用，这些努力才见到成效。</text>
 <text class='lessoncontent'>我们回过头来看这个停止标志识别的例子。神经网络是调制、训练出来的，时不时还是很容易出错的。它最需要的，就是训练。需要成百上千甚至几百万张图像来训练，直到神经元的输入的权值都被调制得十分精确，无论是否有雾，晴天还是雨天，每次都能得到正确的结果。</text>
 <text class='lessoncontent'>只有这个时候，我们才可以说神经网络成功地自学习到一个停止标志的样子；或者在Facebook的应用里，神经网络自学习了你妈妈的脸；又或者是2012年吴恩达（Andrew Ng）教授在Google实现了神经网络学习到猫的样子等等。</text>
 <text class='lessoncontent'></text>吴教授的突破在于，把这些神经网络从基础上显著地增大了。层数非常多，神经元也非常多，然后给系统输入海量的数据，来训练网络。在吴教授这里，数据是一千万YouTube视频中的图像。吴教授为深度学习（deep learning）加入了“深度”（deep）。这里的“深度”就是说神经网络中众多的层。
 <text class='lessoncontent'>现在，经过深度学习训练的图像识别，在一些场景中甚至可以比人做得更好：从识别猫，到辨别血液中癌症的早期成分，到识别核磁共振成像中的肿瘤。Google的AlphaGo先是学会了如何下围棋，然后与它自己下棋训练。它训练自己神经网络的方法，就是不断地与自己下棋，反复地下，永不停歇。</text>
 <text class='minititle'>深度学习，给人工智能以璀璨的未来</text>
 <text class='lessoncontent'>深度学习使得机器学习能够实现众多的应用，并拓展了人工智能的领域范围。深度学习摧枯拉朽般地实现了各种任务，使得似乎所有的机器辅助功能都变为可能。无人驾驶汽车，预防性医疗保健，甚至是更好的电影推荐，都近在眼前，或者即将实现。</text>
 <text class='lessoncontent'>人工智能就在现在，就在明天。有了深度学习，人工智能甚至可以达到我们畅想的科幻小说一般。你的C-3PO我拿走了，你有你的终结者就好了。</text>
 <text>\r\n</text>
 <text>\r\n</text>
 <text>\r\n</text>
  <view wx:if = '{{showbottom}}'><!--条件渲染-->
  <view class='bottomstudyleft' bindtap='backtoCat'>课程目录</view>
  <view class='bottomstudyright' bindtap='gotoP'>课程练习</view>
 </view>
</view>